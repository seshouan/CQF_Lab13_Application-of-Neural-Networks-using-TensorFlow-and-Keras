{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7077db-dd9a-41b7-b912-1c549adeeb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory\n",
    "# $ mkdir my_log_dir\n",
    "\n",
    "# To access http://localhost:6006\n",
    "# $tensorboard --logdir=mlogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c5848-046a-4a7e-bd26-3386fe2cc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e098db02-2bb3-4fc3-99c7-ad0a6098fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import tensorflow and keras\n",
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "\n",
    "# check the tensorflow and keras version\n",
    "print(f\" TensorFlow version is {tensorflow.__version__} \\n Keras version is {tensorflow.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f17fe1-6271-4dfb-893f-a780d3001c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29693b41-4c03-4b30-82e0-72e73a70b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# scikit-learn modules\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# tensorflow modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, LSTM\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop \n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "# plotting & outputs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd761eb-4849-4b94-a16d-71e46f4e279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=2022): \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tensorflow.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e5153-a2f4-4f47-9e3d-ee9b3afa7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample dataset\n",
    "X = np.array([i+1 for i in range(60)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79138770-6520-4e28-b166-7a75b4a1c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into 3D\n",
    "X = np.array(X).reshape(20,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4fa0e-d092-44f2-9e06-924a0a04e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X: {X}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8e30b-d159-46bc-a48f-d6910cf276b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea5a96-9d72-4277-9fe9-ae9111c630e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is the sum of the values in the timesteps\n",
    "y = []\n",
    "for each in X:\n",
    "    y.append(each.sum())\n",
    "    \n",
    "# convert to array\n",
    "y = np.array(y)\n",
    "\n",
    "# check the output\n",
    "print(f'y: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3b42a-6ae5-4b82-8f16-643f37189c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c3cd2-7091-49d7-b0dd-86a198f7e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model five\n",
    "nn = Sequential()\n",
    "nn.add(LSTM(50, activation='relu', input_shape=(3, 1)))\n",
    "nn.add(Dense(1))\n",
    "nn.compile(optimizer='adam', loss='mse')\n",
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206e169-09c7-48d5-8f1e-fb53f6c8f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "nn.fit(X, y, batch_size=64, epochs=1000, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca5ddb-7fcb-4220-be38-3e50ea854276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the outcome\n",
    "test_input = np.array([70,71,72])\n",
    "test_input = test_input.reshape((1, 3, 1))\n",
    "test_output = nn.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4edfd6-1008-43a1-8e0e-9760d63e25af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('results', 'lstm_time_series')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94467d49-e153-4aaf-8c48-31a2bf0566ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset from https://github.com/kannansingaravelu/datasets/blob/main/spy.csv\n",
    "# Read data from the locally stored file\n",
    "data = pd.read_csv('data/spy.csv', index_col=0, parse_dates=True)[['Adj Close']]['2000':'2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d069d-1634-4d66-b417-75e64284318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape - has to be 2D\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bb41c-3d56-49df-bd51-e82e780382ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae2074-c944-4a40-a8a3-ad92b6e49a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization \n",
    "plt.figure(figsize=(14,6))\n",
    "plt.title('SPY Price')\n",
    "plt.plot(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175dc8d-ff76-4483-920f-b436871441a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the datasets into training and testing data.\n",
    "train_data, test_data = train_test_split(data, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Output the train and test data size\n",
    "print(f\"Train and Test Size {len(train_data)}, {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15143c9-9423-4eca-bf31-f08f42ac8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features MinMax for training and test datasets\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_data = scaler.fit_transform(train_data)\n",
    "scaled_test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d70f57-49fc-4f63-9f7d-aefbdb37b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence length\n",
    "lookback = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d71311-9305-490b-965e-ace32017234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(data, sequence_length=lookback):\n",
    "    \n",
    "    # create X & y data array\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        X.append(data[i - sequence_length:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    \n",
    "    # Converting x_train and y_train to Numpy arrays\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb50fc-21d2-4736-a682-5f66d4f25358",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = generate_sequence(data=scaled_train_data, sequence_length=lookback)\n",
    "print(f'X_train: {X_train.shape}, y_train {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88750696-42fb-41d8-b914-fc10acebf53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = generate_sequence(data=scaled_test_data, sequence_length=lookback)\n",
    "print(f'X_test: {X_test.shape}, y_test {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a42fe-1d5e-437a-a7a2-52eebe6674e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping array\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "y_train = y_train[:, np.newaxis] \n",
    "\n",
    "# check the array size\n",
    "print(f'X_train Shape: {X_train.shape}, y_train {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6b19d-bfd2-4ef9-a553-5845592c4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping array\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "y_test = y_test[:, np.newaxis] \n",
    "\n",
    "# check the array size\n",
    "print(f'X_test Shape: {X_test.shape}, y_test {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc0a1a-bbb3-4c29-9df7-70b2850eb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "def create_model(hu=256, lookback=60):\n",
    "\n",
    "    tensorflow.keras.backend.clear_session()   \n",
    "    \n",
    "    # using functional api\n",
    "    inputs = Input(shape=(lookback, 1))\n",
    "    lstm = LSTM(units=hu, activation = 'relu', return_sequences=False, name='LSTM')(inputs)\n",
    "    output = Dense(units=1, name='Output')(lstm)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    # specify optimizer separately (preferred method))\n",
    "    # opt = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08)\n",
    "    # adam optimizer seems to perform better for a single lstm\n",
    "    opt = Adam(learning_rate=0.001, epsilon=1e-08)      \n",
    "    \n",
    "    # model compilation\n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac08e3-9832-4c92-a757-1082f9cf43da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm network\n",
    "model = create_model(hu=10, lookback=lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f97fad-adb2-4061-b5d7-1b1e6312cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fccfa4-ecc2-44c6-9504-e2a231ad3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='./images/model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a83147-ea07-40f5-a0b2-d2777dd6d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify callback functions\n",
    "model_path = (results_path / 'model.keras').as_posix()\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=10, monitor='loss', mode='min', verbose=1, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=model_path, verbose=1, monitor='loss', save_best_only=True),\n",
    "    TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7ca02-37f0-482d-ae85-26d3c9acd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=64, \n",
    "                    epochs=500, \n",
    "                    verbose=1,\n",
    "                    callbacks=my_callbacks, \n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcdefbb-0105-440a-a5ad-d8aba430565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6349a3-2133-4c76-857c-599ca8faf59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848eabc-5c00-4d92-9724-7a1dc1a2dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic model instance\n",
    "basemodel = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267cfd49-c1d0-4a2f-ae7f-40b5c6fb3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, acc = np.sqrt(basemodel.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"Untrained model, loss: {:5.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6815907-8115-42a1-a1ec-a93dacdd8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the weights\n",
    "new_model = tensorflow.keras.models.load_model('results/lstm_time_series/model.keras')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c19e9-7fa4-47d4-a51e-8bb51a725983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-evaluate the model\n",
    "loss, acc = np.sqrt(new_model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"Restored model, loss: {:5.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b49d6-9ec3-492a-b7c1-8208c172ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate rmse of loss function of base model\n",
    "train_rmse_scaled = np.sqrt(basemodel.evaluate(X_train, y_train, verbose=0))\n",
    "test_rmse_scaled = np.sqrt(basemodel.evaluate(X_test, y_test, verbose=0))\n",
    "print(f'Train RMSE: {train_rmse_scaled[0]:.4f} | Test RMSE: {test_rmse_scaled[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff977c2-9f49-4b6c-a8db-5df82d652b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate rmse of loss function of best model\n",
    "train_rmse_scaled = np.sqrt(new_model.evaluate(X_train, y_train, verbose=0))\n",
    "test_rmse_scaled = np.sqrt(new_model.evaluate(X_test, y_test, verbose=0))\n",
    "print(f'Train RMSE: {train_rmse_scaled[0]:.4f} | Test RMSE: {test_rmse_scaled[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760395a-de1b-4f97-a2fe-423b138ecf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred = new_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f101bedf-63f0-4880-9235-bff7cfaf5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'actual': scaler.inverse_transform(y_test).flatten(),\n",
    "    'prediction': scaler.inverse_transform(y_pred).flatten()}, \n",
    "    index = test_data[lookback:].index)\n",
    "\n",
    "df['spread'] = df['prediction'] - df['actual']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158cb10-fc4f-41b2-afca-36f807054464",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R-square: {r2_score(df.actual, df.prediction):0.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d9600-23ff-4231-8c76-bfb2b7c3b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(df.actual, color='red', label='actual')\n",
    "ax[0].plot(df.prediction, color='blue', label='prediction')\n",
    "ax[1].hist(df.spread, bins=50, density=True, label='spread')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.suptitle('SPY LSTM Prediction');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
